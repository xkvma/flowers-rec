{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "925e5e7d-3b49-4f05-9fc0-6be4bae18c14",
   "metadata": {},
   "source": [
    "# Flower classification model training notebook\n",
    "In this notebook we finetune a model to classify flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9670efb4-90aa-4a7d-99f8-5e7226439ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as opj\n",
    "import shutil\n",
    "from collections import Counter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515195ce-fd20-45ae-9414-27133a8584c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "from tqdm.autonotebook import tqdm\n",
    "import splitfolders\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28827596-713a-4905-8090-9db5ad78d33c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Download and prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd94a52-952e-4d09-8bba-1ced56fab55d",
   "metadata": {},
   "source": [
    "## 1.1 Download dataset\n",
    "Download dataset from kaggle and visualise some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aeda0c-2dc3-43be-8469-fb6f0ffc1e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_samples(dataset, samples_per_class=5, title=\"Dataset samples\"):\n",
    "    fig, axes = plt.subplots(samples_per_class, len(dataset.classes), figsize=(15, samples_per_class * 2))\n",
    "    fig.suptitle(title, fontsize=15)\n",
    "    axes = axes\n",
    "    for i in range(0, len(dataset.classes)):\n",
    "        idxs = np.where(np.array(dataset.targets) == i)[0]\n",
    "        for j, idx in enumerate(idxs[:samples_per_class]):\n",
    "            if j == 0:\n",
    "                axes[j][i].set_title(idx_to_class[i], fontsize=10)\n",
    "            axes[j][i].imshow(dataset[idx][0])\n",
    "            axes[j][i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b356d1b7-1839-4d4e-a048-f18a42645381",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = kagglehub.dataset_download('alxmamaev/flowers-recognition')\n",
    "dataset_dir = opj(base_path, \"flowers\")\n",
    "dataset = ImageFolder(dataset_dir)\n",
    "\n",
    "idx_to_class = {v:k for k, v in dataset.class_to_idx.items()}\n",
    "targets_names = [idx_to_class[v] for v in dataset.targets]\n",
    "targets = np.array(dataset.targets)\n",
    "n_classes = len(dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de15848c-95fa-45dc-8a5f-979b0ab456d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset summary:\\n {len(dataset)} samples\")\n",
    "for k, v in Counter(dataset.targets).items():\n",
    "    print (f\" * {idx_to_class[k]}: {v} samples ({int(100 * v / len(dataset))}%)\")\n",
    "    \n",
    "visualise_samples(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20bd3f4-644e-41ae-a3f5-bdb0118d10e9",
   "metadata": {},
   "source": [
    "## 1.2 Train/test/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5721a5b-e32e-494e-896a-baba216e4673",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_path = './data/flowers'\n",
    "splitfolders.ratio(\n",
    "    input=dataset_dir, output=splitted_path, seed=RANDOM_SEED, ratio=(0.7, 0.15, 0.15)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d2fbfc-e6cd-4c6b-a452-fc20f8514381",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ImageFolder(opj(splitted_path, \"train\"))\n",
    "val_ds = ImageFolder(opj(splitted_path, \"val\"))\n",
    "test_ds = ImageFolder(opj(splitted_path, \"test\"))\n",
    "class_distribution = {}\n",
    "\n",
    "for ds, split_name in zip((train_ds, val_ds, test_ds), (\"train\", \"test\", \"val\")):\n",
    "    split_count = Counter(ds.targets)\n",
    "    total_samples = sum(split_count.values())\n",
    "    class_distribution[split_name] = {}\n",
    "    for idx, count in split_count.items():\n",
    "        class_distribution[split_name][idx_to_class[idx]] = \\\n",
    "            f\"{count} ({int(100 * count / total_samples)}%)\"\n",
    "    class_distribution[split_name][\"total\"] = total_samples\n",
    "\n",
    "class_distribution_df = pd.DataFrame(class_distribution).T\n",
    "class_distribution_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dc0b18-5531-42c5-aca3-e9994eab976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_ds, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_ds, batch_size=BATCH_SIZE, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c562441-bef6-4518-bb16-02f829299d78",
   "metadata": {},
   "source": [
    "### 1.3 Add augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dc2c4a-2c4e-4823-8ecd-5a4c03f6177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations = v2.Compose([\n",
    "    v2.RandomRotation(degrees=(0, 15)),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.RandomVerticalFlip(p=0.5),\n",
    "    v2.RandomResizedCrop(size=(224, 224), scale=(0.5, 1.0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27878b98-8db9-495f-a656-2a8faa2a4eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 5, figsize=(15, 10))\n",
    "fig.suptitle(\"Augmentations example\", fontsize=15)\n",
    "axes = axes.flatten()\n",
    "dataset.transform = augmentations\n",
    "for i in range(len(axes)):\n",
    "    axes[i].imshow(dataset[0][0])\n",
    "    axes[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20de15d5-1995-4ad9-abe5-3bd0640f4dc2",
   "metadata": {},
   "source": [
    "### 1.4 Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb74778-03fa-49fd-998b-ec098ca9de17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_ds, batch_size=BATCH_SIZE, shuffle=False\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_ds, batch_size=BATCH_SIZE, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e72fe72-a562-4944-8a90-8c584b5e00d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2b7c52-4d0d-426d-b71b-9df3c504aa5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d056aa-e011-4e24-b695-2fbb27b31d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437436aa-9d7a-4178-96f1-82319624587e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffcd3c6-1f9f-4ea5-afb2-9ab3d5192baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97c5474-e095-4501-8001-cc607f810178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bda9befc-4eb4-4078-aba2-98095851c074",
   "metadata": {},
   "source": [
    "# 3. Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202741a2-05bb-40dd-bcf3-10136bffede8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0934f7-1d2c-481c-8994-9b59a4fa4e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbfa1fe-fb1b-48bb-b31b-4d19c518e33b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51154e0a-2211-4ff6-83ef-a64be42d3029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e31c353-c7fc-48b4-aa07-4c2a30b63a4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Convert to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e7cba3-1021-458e-a660-6a0984e2de73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f38aef-59f7-4267-9fbc-637b456b9890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52a3b39-75d6-4b08-a118-b479ed7b680c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df33d762-c395-40f5-bc4d-5ab33c594ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7a045e-52cd-4039-99aa-7c16ffcdca2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf26e53e-8298-4d89-ae03-e4adbcbe9ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2034a2-bb16-4c06-8931-7f4852dd1b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da61c24a-ad74-43f0-ab06-3d2011a64340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
